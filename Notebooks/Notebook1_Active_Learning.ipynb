{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQCBh950qOLe"
   },
   "source": [
    "\n",
    "## Motivation\n",
    "A key problem in deep learning is data efficiency. While excellent performance can be obtained with modern tools, these are often data-hungry, rendering the deployment of deep learning in the real-world challenging for many tasks.  In Active Learning we use a “human in the loop” approach to data labelling, reducing the amount of data that needs to be labelled drastically, and making machine learning applicable when labelling costs would be too high [1].\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGzRmYzpMnLf"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tCc9Ds2Lzqms"
   },
   "source": [
    "## Passive Learning\n",
    "Tasks which involve gathering a large amount of data randomly sampled from the underlying distribution and using this large dataset to train a model that can perform some sort of prediction. This method has many disadvantages:\n",
    "* Too many wasted samples. \n",
    "* Learning is limited by sampling resolution \n",
    "\n",
    "<img src=https://imgur.com/M7Afc39.png width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ewo3mFbzjID"
   },
   "source": [
    "## Active Learning: Definition and Concepts\n",
    "Active Learning is a semi-supervised technique whose main hypothesis is that if a learning algorithm can select the data it wants to learn from, it can perform better than traditional methods with significantly less data for training. In other words, **Active Learning (AL) is an interactive approach to simultaneously build a labelled data set and train a machine learning model.**\n",
    "\n",
    "**How to make machines curious to Learn?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qQrT2uXR63ub"
   },
   "source": [
    "### AL algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPDfcYBHMnLm"
   },
   "source": [
    "1. A relatively large unlabeled dataset is gathered.\n",
    "2. A domain expert labels a few positive examples in the dataset.\n",
    "\n",
    "<img src=https://imgur.com/BHi6GRx.png width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nx8gol6OMnLp"
   },
   "source": [
    "3. A classifier is trained on labeled samples.\n",
    "4. The classifier is applied to the rest of the corpus.\n",
    "\n",
    "<img src=https://imgur.com/ZPya6mX.png width=\"400\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sec3f0qEMnLs"
   },
   "source": [
    "5. Few most “useful” examples are selected (e.g., that increase classification performance).\n",
    "6. The examples labeled by the expert are added to the training set.\n",
    "\n",
    "<img src=https://imgur.com/yCSp1kU.png width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00RU5phDMnLv"
   },
   "source": [
    "7. Goto 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VPAzx2hB7qX5"
   },
   "source": [
    "<img src=https://imgur.com/smisThj.png width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSaZwMqk7qdI"
   },
   "source": [
    "<img src=https://imgur.com/NuD954f.png width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9EkSxsJrCdC4"
   },
   "source": [
    "## Active Learning for Robotics:\n",
    "In Reinforcement Learning the reward function are the feedback signal (labels) that the agent uses to learn a new skill or achieve a new task. Real world tasks often involve high dimensional observations, like images. Unfortunately, in practice, the design of reward functions for robotic skills is very challenging, especially when learning skills from raw observations such as images. \n",
    "\n",
    "<img src=https://bair.berkeley.edu/static/blog/end_to_end/drape.gif width=\"200\">\n",
    "<img src=https://bair.berkeley.edu/static/blog/end_to_end/push.gif width=\"200\">\n",
    "\n",
    "One solution to learn the **rewards** for such tasks from a small number of user-provided goal examples and samples collected by the policy. The RL algorithm then utilizes this updated classifier as reward for learning a policy to achieve the desired goal, and this alternating process continues until the samples collected by the policy are indistinguishable from the user-proved goal examples [2].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yujukzgHZMAl"
   },
   "source": [
    "### Method: \n",
    "1. User provides examples of successful outcomes (80 user-provided examples are used in [2]).\n",
    "2. Learn a reward function on images using a success classifier, in [2]\n",
    "they used a convolutional neural network for learning a success classifier on image data.\n",
    "3. Run RL with this reward\n",
    "4. Actively query the human user: These active queries are selected based\n",
    "on uncertainty estimates from the classifier that is being used as a reward function, and allow us to learn effective rewards from a small number of initial examples.\n",
    "\n",
    "\n",
    "<img src=https://imgur.com/mGli9UF.png width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3SlInM_a1a8"
   },
   "source": [
    "Some example queries made by the algorithm, and the corresponding labels provided by a human user. This data is fed back into the classifier.\n",
    "\n",
    "<img src=https://imgur.com/v41mHCE.png width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1N5cvDyZyjkc"
   },
   "source": [
    "## Classification Uncertainty \n",
    "The simplest measure is the uncertainty of classification defined by ([3] slide 22) $$U(x)=1-P(\\hat{x}|x)$$\n",
    "\n",
    "where x is the instance to be predicted and x^ is the most likely prediction. \n",
    "\n",
    "For example [5], if you have classes [0, 1, 2] and classification probabilities [0.1, 0.2, 0.7], the most likely class according to the classifier is 2 with uncertainty 0.3. If you have three instances with class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mVDJtTKyjuU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "proba = np.array([[0.1 , 0.85, 0.05],\n",
    "                  [0.6 , 0.3 , 0.1 ],\n",
    "                  [0.39, 0.61, 0.0 ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8b67cz5zh3Q"
   },
   "source": [
    "the corresponding uncertainties are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0obFeUhzic1"
   },
   "outputs": [],
   "source": [
    "1 - proba.max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "reV0FrNRztZF"
   },
   "source": [
    "In the above example, the most uncertain sample is the second one. When querying for labels based on this measure, the strategy selects the sample with the highest uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WEADWT0DMnL1"
   },
   "source": [
    "## Active Learning on MNIST\n",
    "First we will introduce `modAL`, a modular active learning framework for Python. modAL is built on top of scikit-learn, but you can also use TensorFlow Keras or PyTorch models, if those are your frameworks of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JgLZlcB2FzwM"
   },
   "outputs": [],
   "source": [
    "!pip install modAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mnL08guWvbq-"
   },
   "source": [
    "To start, you will import the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0BUbIMUtSEu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "## visualization\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g63Z28Pz5320"
   },
   "source": [
    "## Dataset preparation\n",
    "**MNIST** is a dataset which is 60K pictures of handwritten digits with labels and 10K test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTBQ3sXe4tAZ"
   },
   "outputs": [],
   "source": [
    "# Load and prepare the MNIST dataset.\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# create a small dataset to make the training faster\n",
    "x_train = x_train[:5000]\n",
    "y_train = y_train[:5000]\n",
    "\n",
    "# Take 400 samples for validation  neural network will never see it during the training\n",
    "x_test = x_test[:400]\n",
    "y_test = y_test[:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6_uvFu1A1IUU"
   },
   "source": [
    "### Verify the data\n",
    "To verify that the dataset looks correct, let's plot the first 25 images from the training set and display the class name below each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aqWnwgns1KCZ"
   },
   "outputs": [],
   "source": [
    "class_names = ['0', '1', '2', '3', '4',\n",
    "               '5', '6', '7', '8', '9']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([]) # Disable xticks (text labels)\n",
    "    plt.yticks([]) # Disable yticks (text labels)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    # The Minist labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(class_names[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ccUxxxLA8bW"
   },
   "source": [
    "### Data Preprocessing\n",
    "Add a channels dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xVZfwUEPISUJ"
   },
   "outputs": [],
   "source": [
    "print (\"The shape of training examples:  \" , x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0bN_4YKA7-d"
   },
   "outputs": [],
   "source": [
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOsze2-e58oy"
   },
   "source": [
    "For normalization, we can divide the grayscale image points by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V3yGmKjFBWDk"
   },
   "outputs": [],
   "source": [
    "# Convert the samples from integers to floating-point numbers:\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TWQiGu9rfEbG"
   },
   "source": [
    "### Pool-Based Sampling\n",
    "In pool-based sampling the machine has access to a large number of examples  (in our example 1000 samples) and samples from a pool (4000 samples) based on “informativeness.” Informativeness is quantified based on a user-selected metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bhe7fKw5AGjj"
   },
   "outputs": [],
   "source": [
    "# assemble initial data\n",
    "n_initial = 1000\n",
    "initial_idx = np.random.choice(range(len(x_train)), size=n_initial, replace=False)\n",
    "x_initial = x_train[initial_idx]\n",
    "y_initial = y_train[initial_idx]\n",
    "\n",
    "# generate the pool\n",
    "# remove the initial data from the training dataset\n",
    "x_pool = np.delete(x_train, initial_idx, axis=0)\n",
    "y_pool = np.delete(y_train, initial_idx, axis=0)\n",
    "\n",
    "print (\"The shape of training examples:  \" , x_initial[0].shape)\n",
    "print (\"The number of all training examples: \", x_train.shape[0])\n",
    "print (\"The number of training examples with labels: \", x_initial.shape[0])\n",
    "print (\"The number of training examples without labels: \", x_pool.shape[0])\n",
    "print (\"The number of testing examples:  \", x_test.shape[0])\n",
    "print (\"The number of testing examples:  \", x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Gbwt4FbOAA5"
   },
   "source": [
    "### Create the Model\n",
    "Build the `tf.keras.Sequential` model by stacking layers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmipeJAF6NiV"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UGOsMk72XC7"
   },
   "source": [
    "Let's display the architecture of our model so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KA-6q1Mp2XLf"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZyNBFEY2ozX"
   },
   "source": [
    "Above, you can see that the output of every Conv2D and MaxPooling2D layer is a 3D tensor of shape (height, width, channels). The width and height dimensions tend to shrink as you go deeper in the network. The number of output channels for each Conv2D layer is controlled by the first argument (e.g., 32 or 64). Typically, as the width and height shrink, you can afford (computationally) to add more output channels in each Conv2D layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8gZk7bLw9YSJ"
   },
   "source": [
    "The next step is to choose a loss function for training. The `losses.SparseCategoricalCrossentropy` loss compares the predicted label and true label and calculates the loss. It is used in multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ns1o2nV69db4"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OTNdnkqOzXU3"
   },
   "source": [
    "Many models train better if you gradually reduce the learning rate during training. Use `optimizers.schedules` to reduce the learning rate over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSSWZXy9zaOW"
   },
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 1\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "  0.001,\n",
    "  decay_steps=STEPS_PER_EPOCH*1000,\n",
    "  decay_rate=1,\n",
    "  staircase=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNHrppAo3v-Z"
   },
   "source": [
    "### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELiLuJTOz3l9"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_object,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XjdTUFKiBd3w"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "          x_train, \n",
    "          y_train,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wzmfcOnjgcRQ"
   },
   "outputs": [],
   "source": [
    "# evaluate has two output (test_loss, test_acc) only the accuracy output will be used \n",
    "_, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"the accuracy of model after 3 epochs of training: \", test_acc*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zr94KP0ACw8S"
   },
   "source": [
    "### Active Learning\n",
    "Suppose that you can query the label of an unlabelled instance, but it costs you a lot. Which one would you choose? By querying an instance in the uncertain region, surely you obtain more information than querying by random. \n",
    "\n",
    "The key components of any workflow are the **model** you choose, the **informativeness** measure you use and the **query** strategy you apply to request labels. modAL was designed with modularity, flexibility and extensibility in mind. With using the scikit-learn API, it allows you to rapidly create active learning workflows with nearly complete freedom. What is more, you can easily replace parts with your custom built solutions, allowing you to design novel algorithms with ease. With it, instead of choosing from a small set of built-in components, you have the freedom to seamlessly integrate scikit-learn, TensorFlow/Keras or PyTorch models into your algorithm and easily tailor your custom query strategies and uncertainty measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbkH-At6OMMj"
   },
   "outputs": [],
   "source": [
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling # , classifier_margin, classifier_entropy  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KorN0vYWg5o"
   },
   "source": [
    "Use the same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aqk0owIWjhA"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_object,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1N1P6bCp_X7X"
   },
   "outputs": [],
   "source": [
    "# initialize ActiveLearner\n",
    "learner = ActiveLearner(\n",
    "    estimator=model,\n",
    "    query_strategy=uncertainty_sampling,\n",
    "    # the following argumets will be used to train the model (model.fit)\n",
    "    X_training=x_initial, \n",
    "    y_training=y_initial,\n",
    "    epochs=2,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AKRJ7QDGjCt0"
   },
   "source": [
    "Evaluate the model on the test data using `evaluate`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVVfQdZhrzxf"
   },
   "outputs": [],
   "source": [
    "# We'll plot the accuracy scores after we have actively queried the human user.\n",
    "accuracy_scores = []\n",
    "# evaluate has two output (test_loss, test_acc) only the accuracy output will be used \n",
    "_, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"the accuracy of model after 2 epochs of training: \", test_acc*100, \"%\")\n",
    "# add test_acc to the list\n",
    "accuracy_scores.append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZvDvd6Tr70i"
   },
   "source": [
    "Actively query the human user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNLm-uq9MnMi"
   },
   "outputs": [],
   "source": [
    "# query for labels\n",
    "query_idx, query_inst = learner.query(x_pool)\n",
    "# training=False is needed only if there are layers with different\n",
    "# behavior during training versus inference (e.g. Dropout).\n",
    "predictions = model(query_inst, training=False)[0]\n",
    "# the predicted class:\n",
    "class_idx = tf.argmax(predictions).numpy()\n",
    "\n",
    "# print the results\n",
    "print(\"the index of query: \", query_idx)\n",
    "print(\"the network prediction: \", class_idx)\n",
    "print(\"the network output: \", predictions.numpy())\n",
    "plt.imshow(query_inst[0].reshape([28, 28]), cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4lH-5EPDaA2"
   },
   "outputs": [],
   "source": [
    "# supply label for queried instance\n",
    "user_answer = [6]\n",
    "learner.teach(x_pool[query_idx], user_answer)\n",
    "print(\"The right answer was: \", y_pool[query_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qDIDfGl0rMdA"
   },
   "source": [
    "Remove this query from the pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BxGKp710rLRc"
   },
   "outputs": [],
   "source": [
    "x_pool, y_pool = np.delete(x_pool, query_idx, axis=0), np.delete(y_pool, query_idx, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzB2KWc7sUry"
   },
   "source": [
    "Evaluate the model using the test data after the first query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7a9MiT08UKev"
   },
   "outputs": [],
   "source": [
    "# evaluate has two output (test_loss, test_acc) only the accuracy output will be used \n",
    "_, test_acc = model.evaluate(x_test, y_test)\n",
    "# add test_acc to the list\n",
    "accuracy_scores.append(test_acc)\n",
    "print(\"the accuracy of model after the first query \", test_acc*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gkKqRayVsgwB"
   },
   "source": [
    "### Active Learning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uss4K_pxMnMk"
   },
   "outputs": [],
   "source": [
    "n_queries = 6\n",
    "for i in range(n_queries):\n",
    "    query_idx, query_inst = learner.query(x_pool)\n",
    "    plt.title('Digit to label')\n",
    "    plt.imshow(query_inst.reshape(28, 28), cmap=plt.cm.binary)\n",
    "    plt.show()\n",
    "    print(\"Which digit is this?\")\n",
    "    y_new = np.array([int(input())], dtype=int)\n",
    "    print(\"The right answer was: \",y_pool[query_idx])\n",
    "    learner.teach(query_inst, y_new)\n",
    "    x_pool, y_pool = np.delete(x_pool, query_idx, axis=0), np.delete(y_pool, query_idx, axis=0)\n",
    "    _,test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    accuracy_scores.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sXKLsCAiRk4"
   },
   "outputs": [],
   "source": [
    "print(\"the accuracy of model after the five queries \", test_acc*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X46cofxVjkqk"
   },
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-white'):\n",
    "      plt.figure(figsize=(10, 5))\n",
    "      plt.title('Accuracy of your model')\n",
    "      plt.plot(range(n_queries+2), accuracy_scores)\n",
    "      plt.scatter(range(n_queries+2), accuracy_scores)\n",
    "      plt.xlabel('number of queries')\n",
    "      plt.ylabel('accuracy')\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UeXUWjFqUckt"
   },
   "source": [
    "## References:\n",
    "[1] A. Kirsch, \"BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning\"  \n",
    "[2] A. Singh, \"End-to-End Robotic Reinforcement Learning without Reward Engineering\"  \n",
    "[3] J.M. Zöllner, \"Machine Learning 2, Lecture 4\"  \n",
    "[4] https://www.tensorflow.org/tutorials/  \n",
    "[5] https://modal-python.readthedocs.io/   \n",
    "[6] https://medium.com/@ODSC/crash-course-pool-based-sampling-in-active-learning-cb40e30d49df   \n",
    "[7] https://sites.google.com/view/reward-learning-rl/home\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHBRZ4blvZpg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise_02_Active_Learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
